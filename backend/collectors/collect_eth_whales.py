from __future__ import annotations

"""
åŠ¨æ€æ”¶é›† ERC20ï¼ˆé»˜è®¤ WETHï¼‰é²¸é±¼åœ°å€ï¼Œç›´æ¥å†™å…¥ markets.json

ç”¨æ³•ï¼š
    python backend/collectors/collect_eth_whales.py
    python backend/collectors/collect_eth_whales.py --token <ERC20åœ°å€> --top 20 --blocks 200000

ä¾èµ–ï¼š
    pip install python-dotenv web3
"""

import argparse
import json
import os
import time
from pathlib import Path
from typing import Dict, List, Any, Tuple, Optional

from dotenv import load_dotenv
from web3 import Web3

load_dotenv()

BASE_DIR = Path(__file__).resolve().parent
DEFAULT_WETH = "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2"

MAINNET_RPC = (
    os.getenv("MAINNET_RPC")
    or os.getenv("ETH_RPC_URL")
    or os.getenv("MAINNET_HTTP_URL")
    or os.getenv("ALCHEMY_MAINNET_RPC")
)

if not MAINNET_RPC:
    raise RuntimeError(
        "è¯·åœ¨ .env ä¸­é…ç½® MAINNET_RPC / ETH_RPC_URL / MAINNET_HTTP_URL / ALCHEMY_MAINNET_RPC ä¹‹ä¸€"
    )

w3 = Web3(Web3.HTTPProvider(MAINNET_RPC))
if not w3.is_connected():
    raise RuntimeError("æ— æ³•è¿æ¥ä»¥å¤ªåŠä¸»ç½‘ï¼Œè¯·æ£€æŸ¥ RPC åœ°å€æ˜¯å¦æ­£ç¡®ã€ç½‘ç»œæ˜¯å¦å¯è¾¾")


def _resolve_markets_path() -> Path:
    """
    å…¼å®¹ï¼š
      - backend/markets.json
      - backend/collectors/markets.json
    """
    p1 = BASE_DIR / "markets.json"
    p2 = BASE_DIR.parent / "markets.json"
    if p1.exists():
        return p1
    if p2.exists():
        return p2
    return p2


MARKETS_PATH = _resolve_markets_path()

# âœ… topic0 å¿…é¡»æ˜¯ 0x å¼€å¤´
TRANSFER_TOPIC0 = Web3.to_hex(Web3.keccak(text="Transfer(address,address,uint256)"))


def get_latest_block() -> int:
    latest = w3.eth.block_number
    print(f"âœ… mainnet æœ€æ–°åŒºå—: {latest}")
    return latest


def _parse_hex_block(x: Any) -> Optional[int]:
    """æŠŠ '0x16BABA1' è¿™ç§è½¬æˆ intã€‚"""
    if isinstance(x, str) and x.startswith("0x"):
        try:
            return int(x, 16)
        except Exception:
            return None
    return None


def _is_getlogs_too_large(err: Exception) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦æ˜¯ -32005 / >10000 results çš„ getLogs è¶…é™ç±»é”™è¯¯ã€‚
    """
    if not isinstance(err, Exception):
        return False
    msg = str(err).lower()
    if "more than 10000" in msg or "10000 results" in msg:
        return True

    # web3.exceptions.Web3RPCError: {'code': -32005, ...}
    # æœ‰äº› provider ä¼šæŠ› Web3RPCErrorï¼Œå†…å®¹åœ¨ err.args[0] é‡Œæ˜¯ dict
    if hasattr(err, "args") and err.args:
        obj = err.args[0]
        if isinstance(obj, dict) and obj.get("code") == -32005:
            return True
    return False


def _extract_provider_suggested_range(err: Exception) -> Optional[Tuple[int, int]]:
    """
    ä» -32005 æŠ¥é”™é‡Œè§£æ provider å»ºè®®çš„ block rangeï¼Œæ¯”å¦‚ï¼š
      {'code': -32005, 'message': 'query returned more than 10000 results. Try with this block range [0x16BABA1, 0x16BAC56].', ...}
      æˆ– data: {'from': '0x16BABA1', 'to': '0x16BAC56'}
    è¿”å› (from_block, to_block) çš„ intï¼Œå¦‚æœæ‹¿ä¸åˆ°å°± None
    """
    # 1) è§£æ err.args[0] dict
    if hasattr(err, "args") and err.args and isinstance(err.args[0], dict):
        obj = err.args[0]
        data = obj.get("data") or {}
        fb = _parse_hex_block(data.get("from"))
        tb = _parse_hex_block(data.get("to"))
        if fb is not None and tb is not None and fb <= tb:
            return fb, tb

        # message é‡Œä¹Ÿå¯èƒ½åŒ…å« [0x..., 0x...]
        msg = str(obj.get("message") or "")
        lb = msg.find("[0x")
        rb = msg.find("]", lb + 1)
        if lb != -1 and rb != -1:
            inside = msg[lb + 1 : rb]
            parts = [p.strip() for p in inside.split(",")]
            if len(parts) == 2:
                fb2 = _parse_hex_block(parts[0])
                tb2 = _parse_hex_block(parts[1])
                if fb2 is not None and tb2 is not None and fb2 <= tb2:
                    return fb2, tb2

    # 2) å…œåº•ï¼šåœ¨å­—ç¬¦ä¸²é‡Œæ‰¾
    s = str(err)
    lb = s.find("[0x")
    rb = s.find("]", lb + 1)
    if lb != -1 and rb != -1:
        inside = s[lb + 1 : rb]
        parts = [p.strip() for p in inside.split(",")]
        if len(parts) == 2:
            fb = _parse_hex_block(parts[0])
            tb = _parse_hex_block(parts[1])
            if fb is not None and tb is not None and fb <= tb:
                return fb, tb

    return None


def _get_logs_range(token: str, frm: int, to: int) -> List[Dict[str, Any]]:
    """
    å•æ¬¡ get_logsï¼ŒæŠ›å¼‚å¸¸äº¤ç»™ä¸Šå±‚å¤„ç†ã€‚
    """
    return w3.eth.get_logs(
        {
            "fromBlock": frm,
            "toBlock": to,
            "address": token,
            "topics": [TRANSFER_TOPIC0],
        }
    )


def fetch_transfer_logs_via_rpc(
    token: str,
    start_block: int,
    end_block: int,
    initial_step: int = 5000,
    min_step: int = 64,
    max_tries_per_range: int = 10,
) -> List[Dict[str, Any]]:
    """
    ç”¨ eth_getLogs æ‰«æ ERC20 Transfer æ—¥å¿—ã€‚
    âœ… å¤„ç†ä¸¤ç±»æƒ…å†µï¼š
      - å¸¸è§„ï¼šæŒ‰ step æ‰«æ
      - è¶…é™(-32005)ï¼šä¼˜å…ˆä½¿ç”¨ provider â€œå»ºè®®åŒºé—´â€ï¼Œå¦åˆ™äºŒåˆ†ç¼©å°
    """
    token = Web3.to_checksum_address(token)
    logs: List[Dict[str, Any]] = []

    print(
        f"ğŸ“¡ é€šè¿‡ RPC æ‰«æ Transfer æ—¥å¿—: token={token}, blocks=[{start_block}, {end_block}], step={initial_step}"
    )

    step = initial_step
    current = start_block

    while current <= end_block:
        target_to = min(current + step - 1, end_block)

        frm = current
        to = target_to
        tries = 0

        while True:
            tries += 1
            print(f"  Â· æ‰«æåŒºå—åŒºé—´ [{frm}, {to}] ... ", end="", flush=True)
            try:
                part = _get_logs_range(token, frm, to)
                print(f"ok, æœ¬æ®µæ—¥å¿—æ•°={len(part)}")
                logs.extend(part)
                current = to + 1  # âœ… æˆåŠŸæ¨è¿›
                break

            except Exception as e:
                print(f"âš ï¸ {type(e).__name__}: {e}")

                if not _is_getlogs_too_large(e):
                    # éè¶…é™ç±»é”™è¯¯ï¼šè·³è¿‡è¿™ä¸€æ®µï¼Œç»§ç»­
                    print("  âŒ é 10000 é™åˆ¶ç±»é”™è¯¯ï¼Œè·³è¿‡è¯¥æ®µç»§ç»­ã€‚")
                    current = to + 1
                    break

                # è¶…é™ç±»é”™è¯¯ï¼šä¼˜å…ˆç”¨ provider ç»™çš„å»ºè®®åŒºé—´
                suggested = _extract_provider_suggested_range(e)
                if suggested:
                    sf, st = suggested
                    # provider å»ºè®®åŒºé—´é€šå¸¸æ›´å°ä¸”å¯æ‰§è¡Œ
                    sf = max(sf, frm)
                    st = min(st, to)
                    if sf <= st and (sf != frm or st != to):
                        print(f"  â†ªï¸ ä½¿ç”¨ provider å»ºè®®åŒºé—´é‡è¯•: [{sf}, {st}]")
                        frm, to = sf, st
                        continue

                # å¦åˆ™åšäºŒåˆ†ç¼©å°
                if frm >= to:
                    print("  âŒ å·²æ— æ³•ç»§ç»­ç¼©å°ï¼ˆfrm>=toï¼‰ï¼Œè·³è¿‡è¯¥å—ã€‚")
                    current = to + 1
                    break

                width = to - frm + 1
                if width <= min_step:
                    print(f"  âŒ åŒºé—´å®½åº¦å·²<=min_step({min_step})ä»è¶…é™ï¼Œè·³è¿‡è¯¥æ®µã€‚")
                    current = to + 1
                    break

                mid = (frm + to) // 2
                print(f"  â†ªï¸ è¶…é™ï¼ŒäºŒåˆ†ç¼©å°ï¼šå…ˆå°è¯•å·¦åŠ [{frm}, {mid}]")
                to = mid

                if tries >= max_tries_per_range:
                    print("  âŒ å•æ®µé‡è¯•æ¬¡æ•°è¿‡å¤šï¼Œè·³è¿‡è¯¥æ®µç»§ç»­ã€‚")
                    current = target_to + 1
                    break

        # è‡ªé€‚åº”ï¼šå¦‚æœç»å¸¸è¶…é™ï¼Œå¯ä»¥æŠŠ step æ…¢æ…¢è°ƒå°ï¼ˆå¯é€‰ï¼‰
        # è¿™é‡Œä¿æŒç®€å•ï¼Œä¸åŠ¨ stepï¼›ä½ ä¹Ÿå¯ä»¥æ ¹æ®éœ€è¦åŠ¨æ€è°ƒæ•´ stepã€‚

    print(f"âœ… å…±æ”¶é›† Transfer æ—¥å¿— {len(logs)} æ¡")
    return logs


def logs_to_tx_like(logs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    txs: List[Dict[str, Any]] = []
    for log in logs:
        topics = log.get("topics") or []
        data = log.get("data") or "0x"
        if len(topics) < 3:
            continue

        try:
            t1 = topics[1]
            t2 = topics[2]
            t1h = t1.hex() if hasattr(t1, "hex") else Web3.to_hex(t1)
            t2h = t2.hex() if hasattr(t2, "hex") else Web3.to_hex(t2)

            from_addr = "0x" + t1h[-40:]
            to_addr = "0x" + t2h[-40:]

            if isinstance(data, (bytes, bytearray)):
                value = int.from_bytes(data, "big")
            else:
                value = int(str(data), 16)
        except Exception:
            continue

        txs.append({"from": from_addr, "to": to_addr, "value": str(value)})
    return txs


def aggregate_whales(
    txs: List[Dict[str, Any]],
    min_volume_wei: Optional[int] = None,
) -> Dict[str, Dict[str, Any]]:
    stats: Dict[str, Dict[str, Any]] = {}
    for tx in txs:
        try:
            value = int(tx.get("value") or 0)
        except Exception:
            continue
        if value <= 0:
            continue

        from_addr = (tx.get("from") or "").lower()
        to_addr = (tx.get("to") or "").lower()

        for addr in (from_addr, to_addr):
            if not addr or addr == "0x0000000000000000000000000000000000000000":
                continue
            s = stats.setdefault(addr, {"volume": 0, "tx_count": 0})
            s["volume"] += value
            s["tx_count"] += 1

    if min_volume_wei is not None:
        stats = {a: v for a, v in stats.items() if v["volume"] >= min_volume_wei}

    print(f"ğŸ“ˆ å®Œæˆåœ°å€èšåˆï¼Œå€™é€‰åœ°å€æ•°: {len(stats)}")
    return stats


def pick_top_whales(stats: Dict[str, Dict[str, Any]], top_n: int = 10) -> List[Tuple[str, Dict[str, Any]]]:
    whales = sorted(stats.items(), key=lambda kv: kv[1]["volume"], reverse=True)[:top_n]
    print(f"ğŸ† é€‰å‡ºå‰ {len(whales)} åé²¸é±¼åœ°å€:")
    for i, (addr, v) in enumerate(whales, start=1):
        print(f"  #{i} {addr} | volume={v['volume']} Wei | tx_count={v['tx_count']}")
    return whales


def _load_markets_file(path: Path) -> tuple[list[dict[str, Any]], bool]:
    if not path.exists():
        raise RuntimeError(f"{path} ä¸å­˜åœ¨ï¼Œè¯·å…ˆåˆ›å»ºåŸºç¡€ markets.json")
    raw = json.loads(path.read_text(encoding="utf-8"))
    if isinstance(raw, list):
        return raw, False
    if isinstance(raw, dict) and isinstance(raw.get("markets"), list):
        return raw["markets"], True
    raise RuntimeError('markets.json æ ¼å¼ä¸æ”¯æŒï¼ŒæœŸæœ›æ˜¯æ•°ç»„æˆ– {"markets": [...]} ç»“æ„')


def _dump_markets_file(path: Path, markets: list[dict[str, Any]], wrapped: bool):
    raw = {"markets": markets} if wrapped else markets
    path.write_text(json.dumps(raw, indent=2), encoding="utf-8")
    print(f"ğŸ’¾ å·²æ›´æ–° {path}ï¼Œå½“å‰ markets æ€»æ¡æ•°: {len(markets)}")


def update_markets_with_whales(
    whales: List[Tuple[str, Dict[str, Any]]],
    token_address: str,
    network: str = "mainnet",
):
    markets, wrapped = _load_markets_file(MARKETS_PATH)

    filtered: list[dict[str, Any]] = []
    removed = 0
    for m in markets:
        t = (m.get("type") or "").lower()
        label = (m.get("label") or "").upper()
        meta = m.get("meta") or {}
        is_auto = label.startswith("AUTO_WHALE_") or (meta.get("source") == "collect_eth_whales")
        if t in ("whale_eth", "whale") and is_auto:
            removed += 1
            continue
        filtered.append(m)

    print(f"ğŸ§¹ å·²æ¸…ç†æ—§çš„è‡ªåŠ¨é²¸é±¼æ¡ç›® {removed} ä¸ªï¼Œå‰©ä½™ {len(filtered)} æ¡ marketsã€‚")

    ts = int(time.time())
    for idx, (addr, v) in enumerate(whales, start=1):
        filtered.append(
            {
                "label": f"AUTO_WHALE_{idx}",
                "address": addr,
                "type": "whale_eth",
                "network": network,
                "meta": {
                    "source": "collect_eth_whales",
                    "token": token_address,
                    "rank": idx,
                    "volume_wei": str(v["volume"]),
                    "tx_count": int(v["tx_count"]),
                    "timestamp": ts,
                },
            }
        )

    _dump_markets_file(MARKETS_PATH, filtered, wrapped)


def main():
    parser = argparse.ArgumentParser(description="åŠ¨æ€æ”¶é›† ERC20 é²¸é±¼åœ°å€å¹¶å†™å…¥ markets.json")
    parser.add_argument("--token", type=str, default=DEFAULT_WETH, help="è¦åˆ†æçš„ ERC20 Token åœ°å€ï¼Œé»˜è®¤ä¸»ç½‘ WETH")
    parser.add_argument("--blocks", type=int, default=200_000, help="å›æº¯å¤šå°‘åŒºå—èŒƒå›´ï¼ˆé»˜è®¤ 200kï¼‰")
    parser.add_argument("--top", type=int, default=10, help="é€‰å‡ºå‰å¤šå°‘åé²¸é±¼åœ°å€ï¼ˆé»˜è®¤ 10ï¼‰")
    parser.add_argument(
        "--min-volume-eth",
        type=float,
        default=0.0,
        help="è¿‡æ»¤æœ€å°ç´¯è®¡æˆäº¤é¢ï¼ˆæŒ‰ 18 decimals æ¢ç®—ï¼ŒWETH/ETH é€‚ç”¨ï¼‰ï¼Œæ¯”å¦‚ 50 è¡¨ç¤º â‰¥50",
    )
    parser.add_argument("--step", type=int, default=5000, help="åˆå§‹æ‰«ææ­¥é•¿ï¼ˆé»˜è®¤ 5000ï¼‰ï¼Œçˆ† 10k å°±ä¼šè‡ªåŠ¨ç¼©")
    args = parser.parse_args()

    token = Web3.to_checksum_address(args.token)
    latest = get_latest_block()
    start = max(0, latest - args.blocks)

    raw_logs = fetch_transfer_logs_via_rpc(
        token=token,
        start_block=start,
        end_block=latest,
        initial_step=max(64, int(args.step)),
    )

    tx_like = logs_to_tx_like(raw_logs)

    min_volume_wei = None
    if args.min_volume_eth and args.min_volume_eth > 0:
        min_volume_wei = int(args.min_volume_eth * 10**18)

    stats = aggregate_whales(tx_like, min_volume_wei=min_volume_wei)
    whales = pick_top_whales(stats, top_n=args.top)

    update_markets_with_whales(whales, token_address=token, network="mainnet")


if __name__ == "__main__":
    main()
